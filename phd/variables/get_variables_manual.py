import reimport jsonimport globimport numpy as npimport dask.array as daimport xarray as xrfrom datetime import datetimefrom phd.utils.timer import Timerclass GetVariablesWRF:    def __init__(self, config_path=None, filename=None):        self.config_path = config_path        self.filename = filename        self.ds = None        self.absolute_vorticity = None        self.lats = None        self.lons = None        self.u = None        self.v = None        self.w = None        # Load configuration if config_path is provided.        if self.config_path is not None:            config = self.get_config()            self.filename = config.get('filename')            self.directory = config.get('directory')            self.domain = config.get('domain')            self.start_time = config.get('start_time')            self.end_time = config.get('end_time')    def get_config(self):        """Load the configuration from a JSON file."""        with open(self.config_path, 'r') as config_file:            config = json.load(config_file)        return config    def get_files(self):        """        Retrieves a list of WRF output files within the specified time range.        """        start_time_dt = datetime.strptime(self.start_time, "%H:%M:%S")        end_time_dt = datetime.strptime(self.end_time, "%H:%M:%S")        files = sorted(glob.glob(f"{self.directory}/wrfout_{self.domain}_*"))        pattern = rf"wrfout_{self.domain}_\d{{4}}-\d{{2}}-\d{{2}}_(\d{{2}}-\d{{2}}-\d{{2}})"        selected_files = []        for file in files:            match = re.search(pattern, file)            if match:                file_time_str = match.group(1).replace("-", ":")                try:                    file_time_dt = datetime.strptime(file_time_str, "%H:%M:%S")                    if start_time_dt <= file_time_dt <= end_time_dt:                        selected_files.append(file)                except ValueError:                    print(f"Warning: Time format mismatch in file {file}. Skipping.")        return selected_files    def open_dataset(self):        """Open the dataset from either a single file or multiple files, as applicable."""        if self.ds is None:            if self.filename is not None:                self.ds = xr.open_dataset(self.filename)            elif self.directory is not None and self.start_time is not None and self.end_time is not None:                files = self.get_files()                self.ds = xr.open_mfdataset(files, combine='nested', concat_dim='Time')            else:                raise ValueError("Either filename or directory with start_time and end_time must be provided.")    def close_dataset(self):        """Close the dataset if it's open."""        if self.ds is not None:            self.ds.close()            self.ds = None    def de_stagger(self, var, axis):        """De-stagger a variable along a specified axis using xarray, automatically renaming the dimension."""        # Rechunk the data along the destaggered axis to ensure consistent chunk sizes        # Get the current chunks along the axis        current_chunks = var.chunks[var.get_axis_num(axis)]        min_chunk_size = min(current_chunks)                # If the minimum chunk size is 1, rechunk to combine small chunks        if min_chunk_size == 1:            # Determine the total size along the axis            total_size = var.sizes[axis]            # Rechunk to a size that evenly divides the total size (if possible)            desired_chunk_size = total_size // max(1, total_size // max(current_chunks))            var = var.chunk({axis: desired_chunk_size})                # Perform destaggering        destaggered_var = 0.5 * (var.isel({axis: slice(1, None)}) + var.isel({axis: slice(None, -1)}))        new_dim_name = axis.replace('_stag', '')        destaggered_var = destaggered_var.rename({axis: new_dim_name})                # Rechunk the destaggered variable to merge any small chunks        # Here, we can use 'auto' or specify a desired chunk size        destaggered_var = destaggered_var.chunk({new_dim_name: 'auto'})                return destaggered_var    def find_closest_height_level(self, height_field, target_height=5):        """Find the closest height level to the target height using masking."""        abs_diff = np.abs(height_field - target_height)        # Create a mask for the minimum height difference        mask = abs_diff == abs_diff.min(dim="bottom_top")        return mask    def extract_variable_at_height(self, var, target_height=5):        """        Extract a variable (e.g., U or V) at the specified height level using interpolation.        """        var_at_height = var.interp(bottom_top=target_height, method="nearest")        return var_at_height    def get_lat_lons(self):        """Retrieve latitude and longitude coordinates."""        self.open_dataset()        self.lats = self.ds['XLAT']        self.lons = self.ds['XLONG']                if self.lats.ndim == 3 and self.lons.ndim == 3:            self.lats = self.lats[0]            self.lons = self.lons[0]        else:            pass                return self.lats, self.lons    def get_coriolis_parameter(self, lats):        """Calculate Coriolis parameter based on latitude in degrees."""        omega = 7.2921159e-5  # Earth's rotation rate (rad/s)        lat_radians = np.radians(lats)        f = 2 * omega * np.sin(lat_radians)        return f        def get_geopotential_height(self):        """Calculate full geopotential height from perturbation and base geopotential, retaining DataArray properties."""        self.open_dataset()        PH = self.de_stagger(self.ds['PH'], axis='bottom_top_stag')        PHB = self.de_stagger(self.ds['PHB'], axis='bottom_top_stag')        geopotential_height = (PH + PHB) / 9.81                # Retrieve terrain height (HGT)        HGT = self.ds['HGT']        if 'Time' not in HGT.dims:            HGT = HGT.expand_dims('Time')            # Calculate height above ground level (AGL)        height_agl = geopotential_height - HGT        return height_agl    def get_vertical_resolution(self):        """Calculate vertical resolution (dz) at each model level using Dask's gradient function."""        height_agl = self.get_geopotential_height()  # xarray DataArray backed by Dask array            # Get the axis number for 'bottom_top'        axis_num = height_agl.get_axis_num('bottom_top')            # Compute dz using Dask's gradient function along the vertical axis        dz_data = da.gradient(height_agl.data, axis=axis_num)            # Create a DataArray from dz_data        dz = xr.DataArray(dz_data, dims=height_agl.dims, coords=height_agl.coords)            return dz    def get_wind_components(self):        """Extract and destagger the wind components U, V, and W."""        self.open_dataset()        self.u = self.de_stagger(self.ds['U'], axis='west_east_stag')        self.v = self.de_stagger(self.ds['V'], axis='south_north_stag')        self.w = self.de_stagger(self.ds['W'], axis='bottom_top_stag')        return self.u, self.v, self.w    def get_wind_components_at_heights(self, height=500):        """Extract U and V wind components at a specific height."""        self.get_wind_components()        # Calculate geopotential height        height_field = self.get_geopotential_height()        # Find closest height level to target height        height_idx = self.find_closest_height_level(height_field, height)                    self.u_hgt = self.extract_variable_at_height(self.u, height_idx)        self.v_hgt = self.extract_variable_at_height(self.v, height_idx)                    return self.u_hgt, self.v_hgt    @Timer    def get_absolute_vorticity(self, height=500):        """Calculate absolute vorticity at a specified height above ground level (e.g., 500m AGL)."""        self.open_dataset()        self.get_lat_lons()        # De-stagger U and V to a consistent grid        self.get_wind_components()        u = self.u        v = self.v                # Get wind components and desired target height        u_at_height = self.extract_variable_at_height(u)        v_at_height = self.extract_variable_at_height(v)                # Calculate gradients for relative vorticity using numpy's gradient        dx = self.ds.attrs['DX']        dy = self.ds.attrs['DY']        dv_dx = da.gradient(v_at_height.data, dx, axis=-1)        du_dy = da.gradient(u_at_height.data, dy, axis=-2)        # Calculate Coriolis parameter        f = self.get_coriolis_parameter(self.lats)        f = f.expand_dims("bottom_top").isel(bottom_top=0)        f = f.broadcast_like(u_at_height)        # Calculate absolute vorticity        zeta = dv_dx - du_dy                absolute_vorticity = (zeta + f)        self.absolute_vorticity = absolute_vorticity * 1000  # Convert to desired units.        return self.absolute_vorticity    @Timer    def get_full_absolute_vorticity(self):        """Calculate full absolute vorticity."""        self.open_dataset()        self.get_lat_lons()                # De-stagger U and V to a consistent grid        self.get_wind_components()        u = self.u.data        v = self.v.data        w = self.w.data        # Calculate gradients for relative vorticity using numpy's gradient        dx = self.ds.attrs['DX']        dy = self.ds.attrs['DY']        dz = self.get_vertical_resolution().data                dv_dx = da.gradient(v, dx, axis=-1)        du_dy = da.gradient(u, dy, axis=-2)        dw_dx = da.gradient(w, dx, axis=-1)        dw_dy = da.gradient(w, dy, axis=-2)        du_dz = da.gradient(u, axis=-3) / dz        dv_dz = da.gradient(v, axis=-3) / dz        dw_dz = da.gradient(w, axis=-3) / dz                # Calculate relative vorticity (Î¶ = dv/dx - du/dy)        zeta = dv_dx - du_dy            # Extract dimensions        n_bottom_top = self.ds.sizes['bottom_top']        n_time = self.ds.sizes['Time']        # Calculate Coriolis parameter        f = self.get_coriolis_parameter(self.lats)        f = np.repeat(f.values[np.newaxis, :, :], n_bottom_top, axis=0)        f = np.repeat(f[np.newaxis, :, :, :], n_time, axis=0)         # Convert expanded f to xarray.DataArray        f = xr.DataArray(            f,            dims=["Time", "bottom_top", "south_north", "west_east"],            coords={                "Time": self.ds.Time,                "bottom_top": self.ds.bottom_top,                "south_north": self.lats.south_north,                "west_east": self.lats.west_east            }        )                absolute_vorticity = (zeta + f)                self.stretching_term = absolute_vorticity * dw_dz        self.tilting_term = -(dw_dx * dv_dz - dw_dy * du_dz)        # Wrap tilting_term into an xarray.DataArray        self.tilting_term = xr.DataArray(            self.tilting_term,            dims=["Time", "bottom_top", "south_north", "west_east"],            coords={                "Time": self.ds["Time"],                "bottom_top": self.ds["bottom_top"],                "south_north": self.ds["south_north"],                "west_east": self.ds["west_east"]            },            name="tilting_term"        )                        self.absolute_vorticity = absolute_vorticity * 1000  # Convert to desired units.                return self.absolute_vorticity, self.stretching_term, self.tilting_term        def __del__(self):        """Ensure that the dataset is closed when the object is deleted."""        self.close_dataset()